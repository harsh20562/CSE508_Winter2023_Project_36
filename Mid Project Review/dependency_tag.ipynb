{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058a93ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ebd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('liar_dataset/train.tsv', sep='\\t', header=None)\n",
    "df.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'party_affiliation', 'barely_true', 'false', 'half_true', 'mostly_true', 'pants_on_fire', 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f1aa8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_21736\\184754304.py:5: DeprecationWarning: The StanfordParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
      "  parser = stanford.StanfordParser(model_path=os.path.join(stanford_dir, \"englishPCFG.ser.gz\"))\n"
     ]
    }
   ],
   "source": [
    "stanford_dir = r\"C:\\Users\\Ayush\\Desktop\\Jars\"\n",
    "os.environ['STANFORD_PARSER'] = os.path.join(stanford_dir, \"stanford-parser.jar\")\n",
    "os.environ['STANFORD_MODELS'] = os.path.join(stanford_dir, \"stanford-parser-4.2.0-models.jar\")\n",
    "\n",
    "parser = stanford.StanfordParser(model_path=os.path.join(stanford_dir, \"englishPCFG.ser.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12fdbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the JAVAHOME environment variable to the path to your Java installation directory\n",
    "java_path = r\"C:\\Program Files\\Java\\jdk-19\"\n",
    "os.environ['JAVAHOME'] = java_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5ab233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\r\n",
      "SLF4J: Found binding in [jar:file:/C:/Users/Ayush/Desktop/Jars/slf4j-simple.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\n",
      "SLF4J: Found binding in [jar:file:/C:/Users/Ayush/Desktop/Jars/stanford-parser-full-2020-11-17/slf4j-simple.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory]\r\n",
      "[main] INFO edu.stanford.nlp.parser.lexparser.LexicalizedParser - Loading parser from serialized file C:\\Users\\Ayush\\Desktop\\Jars\\englishPCFG.ser.gz ... done [1.5 sec].\r\n",
      "Parsing file: C:\\Users\\Ayush\\AppData\\Local\\Temp\\tmp8c0jb84y\r\n",
      "Parsing [sent. 1 len. 546]: Hospitals , doctors , MRIs , surgeries and so forth are more extensively used and far more expensive in this country than they are in many other countries . '' health-care mitt-romney Former governor Massachusetts republican 34 32 58 33 19 a Fox News Sunday interview 9874.json barely-true Obamacare cuts seniors Medicare . health-care , medicare ed-gillespie Republican strategist Washington , D.C. republican 2 3 2 2 1 a campaign email . 3072.json mostly-true The refusal of many federal employees to fly coach costs taxpayers $ 146 million annually . government-efficiency , transparency newsmax Magazine and website Florida none 0 0 0 1 0 an e-mail solicitation 2436.json mostly-true Florida spends more than $ 300 million a year just on children repeating pre-K through 3rd grade . education alex-sink Florida democrat 1 2 2 4 0 figures cites on campaign website 9721.json true Milwaukee County Sheriff David A. Clarke Jr. advised citizens to point that barrel center mass and pull the trigger because 911 is not our best option . crime , criminal-justice , guns , legal-issues greater-wisconsin-political-fund Wisconsin none 3 3 3 1 1 a campaign TV ad 3627.json false Almost 37 percent of the total income from Planned Parenthood is from abortions . abortion ronald-renuart State Representative Florida republican 0 1 0 0 0 comments during a committee hearing 11900.json half-true The United States has the highest rate of childhood poverty of almost any major country on Earth . children , poverty bernie-s U.S . Senator Vermont independent 18 12 22 41 0 comments during the PBS Democratic debate 4611.json true Under Governor Almond the RI DMV had a program that allowed undocumented [ people to ] use their Personal Tax Identification Number . . . to apply [ for ] and receive a RI drivers license . civil-rights , homeland-security , immigration , public-safety , transportation , workers david-quiroa prresident , Guatemalan-American Alliance of Rhode Island Rhode Island newsmaker 0 0 0 0 0 a news release 3168.json pants-fire Illegal aliens cost the state of Rhode Island $ 400 million a year . census , crime , education , health-care , immigration , state-budget , taxes terry-gorman President , Rhode Islanders for Immigration Law Enforcement Rhode Island newsmaker 1 0 0 0 1 a radio interview 6832.json pants-fire Says Eric Cantor voted to assure Congress would be paid if the government shut down and against guaranteeing troops would be paid . congressional-rules , federal-budget , military wayne-powell lawyer Virginia democrat 1 1 0 0 1 a debate . 5893.json mostly-true If Congress froze the current spending level and then cut it by 2 percent annually , we could balance the budget in five years . deficit , federal-budget jamie-radtke Virginia republican 1 1 1 2 0 a statement 3304.json true Every ( Wisconsin ) legislator that votes for this bill will have to give up the same amount of pay as other state employees . labor , state-budget jeff-fitzgerald Incoming speaker of state Assembly Wisconsin republican 2 0 1 2 2 an interview on the Fox News Channel 1638.json half-true Marco Rubio controlled funds that out of the $ 600,000 that were raised , only $ 4,000 went to candidates to try to improve their chances to be elected to office . ''\r\n",
      "Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\r\n",
      "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parseAndReport(LexicalizedParserQuery.java:706)\r\n",
      "\tat edu.stanford.nlp.parser.lexparser.ParseFiles.parseFiles(ParseFiles.java:215)\r\n",
      "\tat edu.stanford.nlp.parser.lexparser.ParseFiles.parseFiles(ParseFiles.java:75)\r\n",
      "\tat edu.stanford.nlp.parser.lexparser.LexicalizedParser.main(LexicalizedParser.java:1491)\r\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['C:\\\\Program Files\\\\Java\\\\jdk-19\\\\bin\\\\java.exe', '-mx4g', '-cp', 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-core-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-core-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-ddense-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-ddense-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-simple-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-simple-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-api-1.7.12-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-api.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-simple.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-javadoc.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-core-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-core-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-ddense-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-ddense-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-simple-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-simple-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-api-1.7.12-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-api.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-simple.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-javadoc.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser.jar', 'edu.stanford.nlp.parser.lexparser.LexicalizedParser', '-model', 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\englishPCFG.ser.gz', '-sentences', 'newline', '-outputFormat', 'penn', '-tokenized', '-escaper', 'edu.stanford.nlp.process.PTBEscapingProcessor', '-encoding', 'utf8', 'C:\\\\Users\\\\Ayush\\\\AppData\\\\Local\\\\Temp\\\\tmp8c0jb84y']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_sent\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Parse the 'Statement' column in the dataset\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDependencies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Print the dependencies for the first statement in the dataset\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mparse_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(sentence)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Perform dependency parsing\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m parsed_sent \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Return the list of dependencies\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_sent\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\api.py:47\u001b[0m, in \u001b[0;36mParserI.parse\u001b[1;34m(self, sent, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m:return: An iterator that generates parse trees for the sentence.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    When possible this list is sorted from most likely to least likely.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m:rtype: iter(Tree)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overridden(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_sents):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_sents([sent], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m overridden(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_one):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m         tree\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_one(sent, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tree \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\stanford.py:136\u001b[0m, in \u001b[0;36mGenericStanfordParser.parse_sents\u001b[1;34m(self, sentences, verbose)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03mUse StanfordParser to parse multiple sentences. Takes multiple sentences as a\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03mlist where each sentence is a list of words.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m:rtype: iter(iter(Tree))\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_MAIN_CLASS,\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medu.stanford.nlp.process.PTBEscapingProcessor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m ]\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_trees_output(\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\stanford.py:258\u001b[0m, in \u001b[0;36mGenericStanfordParser._execute\u001b[1;34m(self, cmd, input_, verbose)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mappend(input_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 258\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mjava\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasspath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_classpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xc2\u001b[39;00m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py:140\u001b[0m, in \u001b[0;36mjava\u001b[1;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_decode_stdoutdata(stderr))\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava command failed : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(cmd))\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (stdout, stderr)\n",
      "\u001b[1;31mOSError\u001b[0m: Java command failed : ['C:\\\\Program Files\\\\Java\\\\jdk-19\\\\bin\\\\java.exe', '-mx4g', '-cp', 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-core-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-core-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-ddense-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-ddense-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-simple-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\ejml-simple-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-api-1.7.12-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-api.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\slf4j-simple.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-javadoc.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-4.2.0-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-core-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-core-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-ddense-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-ddense-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-simple-0.38.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\ejml-simple-0.39-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-api-1.7.12-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-api.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\slf4j-simple.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-javadoc.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-models.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser-4.2.0-sources.jar;C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\stanford-parser-full-2020-11-17\\\\stanford-parser.jar', 'edu.stanford.nlp.parser.lexparser.LexicalizedParser', '-model', 'C:\\\\Users\\\\Ayush\\\\Desktop\\\\Jars\\\\englishPCFG.ser.gz', '-sentences', 'newline', '-outputFormat', 'penn', '-tokenized', '-escaper', 'edu.stanford.nlp.process.PTBEscapingProcessor', '-encoding', 'utf8', 'C:\\\\Users\\\\Ayush\\\\AppData\\\\Local\\\\Temp\\\\tmp8c0jb84y']"
     ]
    }
   ],
   "source": [
    "def parse_sentence(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # Perform dependency parsing\n",
    "    parsed_sent = parser.parse(tokens)\n",
    "    # Return the list of dependencies\n",
    "    return parsed_sent\n",
    "\n",
    "\n",
    "# Parse the 'Statement' column in the dataset\n",
    "df['Dependencies'] = df['statement'].apply(parse_sentence)\n",
    "\n",
    "# Print the dependencies for the first statement in the dataset\n",
    "print(df['statement'][0])\n",
    "for dependency in df['Dependencies'][0]:\n",
    "    print(f\"{dependency[0]} --{dependency[1]}--> {dependency[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0164973a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_21736\\678472425.py:3: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
      "  dep_tree = nltk.parse.DependencyGraph(nltk.parse.stanford.StanfordDependencyParser().raw_parse(text))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DependencyGraph' object has no attribute 'rstrip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     dep_tree \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mDependencyGraph(nltk\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mstanford\u001b[38;5;241m.\u001b[39mStanfordDependencyParser()\u001b[38;5;241m.\u001b[39mraw_parse(text))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep_tree\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_tree\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep_parsing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliar_dataset_parsed.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mdep_parsing\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdep_parsing\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(text)\n\u001b[1;32m----> 3\u001b[0m     dep_tree \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDependencyGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstanford\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStanfordDependencyParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep_tree\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:78\u001b[0m, in \u001b[0;36mDependencyGraph.__init__\u001b[1;34m(self, tree_str, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tree_str:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtree_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcell_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_based\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcell_separator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell_separator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_relation_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_relation_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:318\u001b[0m, in \u001b[0;36mDependencyGraph._parse\u001b[1;34m(self, input_, cell_extractor, zero_based, cell_separator, top_relation_label)\u001b[0m\n\u001b[0;32m    315\u001b[0m lines \u001b[38;5;241m=\u001b[39m (l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lines \u001b[38;5;28;01mif\u001b[39;00m l)\n\u001b[0;32m    317\u001b[0m cell_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    319\u001b[0m     cells \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(cell_separator)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cell_number \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:315\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    312\u001b[0m     input_ \u001b[38;5;241m=\u001b[39m (line \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    314\u001b[0m lines \u001b[38;5;241m=\u001b[39m (l\u001b[38;5;241m.\u001b[39mrstrip() \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m input_)\n\u001b[1;32m--> 315\u001b[0m lines \u001b[38;5;241m=\u001b[39m (l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lines \u001b[38;5;28;01mif\u001b[39;00m l)\n\u001b[0;32m    317\u001b[0m cell_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\parse\\dependencygraph.py:314\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    312\u001b[0m     input_ \u001b[38;5;241m=\u001b[39m (line \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 314\u001b[0m lines \u001b[38;5;241m=\u001b[39m (\u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstrip\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m input_)\n\u001b[0;32m    315\u001b[0m lines \u001b[38;5;241m=\u001b[39m (l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lines \u001b[38;5;28;01mif\u001b[39;00m l)\n\u001b[0;32m    317\u001b[0m cell_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DependencyGraph' object has no attribute 'rstrip'"
     ]
    }
   ],
   "source": [
    "def dep_parsing(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    dep_tree = nltk.parse.DependencyGraph(nltk.parse.stanford.StanfordDependencyParser().raw_parse(text))\n",
    "    return dep_tree\n",
    "\n",
    "df['dep_tree'] = df['statement'].apply(dep_parsing)\n",
    "df.to_csv('liar_dataset_parsed.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
