{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "xKVv2aDiTQ7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_-7JD__fTqZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zeq4FNzjSgqT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import TFAutoModel, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('drive/MyDrive/liar_dataset/train.tsv',sep='\\t', header=None, names=['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'])\n",
        "test_df = pd.read_csv('drive/MyDrive/liar_dataset/test.tsv',sep='\\t', header=None, names=['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'])\n",
        "val_df = pd.read_csv('drive/MyDrive/liar_dataset/valid.tsv',sep='\\t', header=None, names=['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'])"
      ],
      "metadata": {
        "id": "iNgOhySHSydw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "X = df['statement'].values\n",
        "X = tokenizer(X.tolist(), padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
        "y = pd.get_dummies(df['label']).values\n",
        "\n",
        "X_train = [X['input_ids'].numpy()[0:train_df.shape[0]], X['attention_mask'].numpy()[0:train_df.shape[0]]]\n",
        "y_train = y[:train_df.shape[0]]\n",
        "X_test = [X['input_ids'].numpy()[train_df.shape[0]:], X['attention_mask'].numpy()[train_df.shape[0]:]]\n",
        "y_test = y[train_df.shape[0]:]\n",
        "\n",
        "bert_model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "input_ids = tf.keras.layers.Input(shape=(128,), dtype='int32')\n",
        "input_masks = tf.keras.layers.Input(shape=(128,), dtype='int32')\n",
        "bert_output = bert_model({'input_ids': input_ids, 'attention_mask': input_masks})[0]\n",
        "output_layer = tf.keras.layers.Dense(6, activation='softmax')(bert_output[:, 0, :])\n",
        "model = tf.keras.models.Model(inputs=[input_ids, input_masks], outputs=output_layer)\n",
        "for layer in model.layers[:4]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "SxQxoM55SpWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "B7O_NctjTdpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_metric])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "n2EJHo9FSr7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}