{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W0eKGgAupeC",
        "outputId": "ad7fabe1-cbd5-4e33-b145-0c4e6e89ed68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "CQRbcx0iurFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/liar_dataset/train.tsv\", sep=\"\\t\", header=None)\n",
        "df_train.columns = ['json_ID', 'label','statement','subject','speaker','speaker_job','state_info','party_affiliation','barely_true_counts','false_counts','half_true_counts','mostly_true_counts','pants_on_fire_counts','context']\n",
        "\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/liar_dataset/test.tsv\", sep=\"\\t\", header=None)\n",
        "df_test.columns = ['json_ID', 'label','statement','subject','speaker','speaker_job','state_info','party_affiliation','barely_true_counts','false_counts','half_true_counts','mostly_true_counts','pants_on_fire_counts','context']\n",
        "\n",
        "df_validate = pd.read_csv(\"/content/drive/MyDrive/liar_dataset/valid.tsv\", sep=\"\\t\", header=None)\n",
        "df_validate.columns = ['json_ID', 'label','statement','subject','speaker','speaker_job','state_info','party_affiliation','barely_true_counts','false_counts','half_true_counts','mostly_true_counts','pants_on_fire_counts','context']\n",
        "\n",
        "df_train['label'] = df_train['label'].map({'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5})\n",
        "df_test['label'] = df_test['label'].map({'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5})\n",
        "df_validate['label'] = df_validate['label'].map({'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5})"
      ],
      "metadata": {
        "id": "m_dhh2Afusmt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def preprocess_text(input_text):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    token_type_ids = []\n",
        "    \n",
        "    for text in input_text:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=128,\n",
        "                            padding='max_length',\n",
        "                            truncation=True,\n",
        "                            return_attention_mask=True,\n",
        "                            return_token_type_ids=True,\n",
        "                            return_tensors='np'\n",
        "                       )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "    return {'input_ids': np.array(input_ids),\n",
        "            'attention_mask': np.array(attention_masks),\n",
        "            'token_type_ids': np.array(token_type_ids)}"
      ],
      "metadata": {
        "id": "hz-NqZoTut-p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = preprocess_text(df_train['statement'].values)\n",
        "y_train = df_train['label'].values\n",
        "\n",
        "X_test = preprocess_text(df_test['statement'].values)\n",
        "y_test = df_test['label'].values\n",
        "\n",
        "X_validate = preprocess_text(df_validate['statement'].values)\n",
        "y_validate = df_validate['label'].values"
      ],
      "metadata": {
        "id": "Huu9hc27uvTo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(X_train['input_ids'], dtype=torch.long)\n",
        "train_labels = torch.tensor(y_train, dtype=torch.long)\n",
        "train_masks = torch.tensor(X_train['attention_mask'], dtype=torch.long)\n",
        "train_token_types = torch.tensor(X_train['token_type_ids'], dtype=torch.long)\n",
        "\n",
        "test_inputs = torch.tensor(X_test['input_ids'], dtype=torch.long)\n",
        "test_labels = torch.tensor(y_test, dtype=torch.long)\n",
        "test_masks = torch.tensor(X_test['attention_mask'], dtype=torch.long)\n",
        "test_token_types = torch.tensor(X_test['token_type_ids'], dtype=torch.long)\n",
        "test_y = torch.tensor(test_labels.tolist())\n",
        "\n",
        "validate_inputs = torch.tensor(X_validate['input_ids'], dtype=torch.long)\n",
        "validate_labels = torch.tensor(y_validate, dtype=torch.long)\n",
        "validate_masks = torch.tensor(X_validate['attention_mask'], dtype=torch.long)\n",
        "validate_token_types = torch.tensor(X_validate['token_type_ids'], dtype=torch.long)\n",
        "val_y = torch.tensor(validate_labels.tolist())"
      ],
      "metadata": {
        "id": "HWSSHpVVuwm_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_token_types, train_labels)\n",
        "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(validate_inputs, validate_masks, validate_token_types, validate_labels)\n",
        "val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_token_types, test_labels)\n",
        "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# Set optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "haH-guY0ux5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, scheduler, device):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch in tqdm(dataloader, desc='Training'):\n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_mask = batch[1].to(device)\n",
        "      token_type_ids = batch[2].to(device)\n",
        "      labels = batch[3].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "      input_ids = input_ids.squeeze(1)\n",
        "      attention_mask = attention_mask.squeeze(1)\n",
        "      token_type_ids = token_type_ids.squeeze(1)\n",
        "      \n",
        "      outputs = model(input_ids, attention_mask=attention_mask, token_type_ids = token_type_ids, labels=labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "  avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "wMZ8Hvkkmlyp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "  model.eval()\n",
        "  \n",
        "  all_preds = []\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch in tqdm(dataloader, desc='Evaluation'):\n",
        "          input_ids = batch[0].to(device)\n",
        "          attention_mask = batch[1].to(device)\n",
        "          token_type_ids = batch[2].to(device)\n",
        "          labels = batch[3].to(device)\n",
        "\n",
        "          model.zero_grad()\n",
        "          input_ids = input_ids.squeeze(1)\n",
        "          attention_mask = attention_mask.squeeze(1)\n",
        "          token_type_ids = token_type_ids.squeeze(1)\n",
        "      \n",
        "          outputs = model(input_ids, attention_mask=attention_mask, token_type_ids = token_type_ids, labels=labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "          all_preds.extend(preds.cpu().numpy())\n",
        "          total_correct += torch.sum(preds == labels).item()\n",
        "          total_samples += labels.shape[0]\n",
        "  \n",
        "  avg_loss = total_loss / len(dataloader)\n",
        "  accuracy = total_correct / total_samples\n",
        "\n",
        "  return avg_loss, all_preds, accuracy"
      ],
      "metadata": {
        "id": "CkkPKN-emrHA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}:')\n",
        "    train_loss = train(model, train_dataloader, optimizer, scheduler, device)\n",
        "    val_loss, val_f1, acc = evaluate(model, val_dataloader, device)\n",
        "    val_f1_score = f1_score(val_y, val_f1, average = 'macro')\n",
        "\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    print(f'Val Accuracy: {acc:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Macro F1 Score: {val_f1_score:.4f}')\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "test_loss, test_f1, test_acc = evaluate(model, test_dataloader, device)\n",
        "test_f1_score = f1_score(test_y, test_f1, average = 'macro')\n",
        "print()\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Macro F1 Score: {test_f1_score:.4f}')"
      ],
      "metadata": {
        "id": "XEBIl8FXnXL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(val_losses, label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQ0ktVEszjid"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}